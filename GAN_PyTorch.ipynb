{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc95924",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413bff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6aaeb",
   "metadata": {},
   "source": [
    "## check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfec1415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#! hell yeah !\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba1625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "BATCH_SIZE = 128\n",
    "AVL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a8eb3",
   "metadata": {},
   "source": [
    "## Class DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a08499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir = \"./data\", \n",
    "                 batch_size = BATCH_SIZE, num_workers = NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train = True, download = True)\n",
    "        MNIST(self.data_dir, train = False, download = True)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        # Assign train/val datasets\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train = True, transform = self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train = False, transform = self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size = self.batch_size, num_workers = self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size = self.batch_size, num_workers = self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42007b8e",
   "metadata": {},
   "source": [
    "## Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7de5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! kho inja ye cnn ba 2 laye darim kheili sade too layer\n",
    "#! akhar 0 ya 1 bar migradoonim\n",
    "#! in yani fake e ya na\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Simple CNN\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten the tensor so it can be fed into the FC layers\\\n",
    "        #! vase flatten az view estefade mikonim vase reshape kardan\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce1d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be4bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a84b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
